{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import nltk\n",
    "\n",
    "import pickle\n",
    "import jieba\n",
    "import h5py\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/liwb/anaconda3/lib/python3.5/site-packages/torch/serialization.py:286: SourceChangeWarning: source code of class 'models.AttnDecoderRNN' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "encoder2 = torch.load('../models/encoder{0}.m{1}'.format('first',60000))\n",
    "decoder2 = torch.load('../models/decoder{0}.m{1}'.format('first',60000))\n",
    "decoder2.dropout = nn.Dropout(0)\n",
    "# encoder2 = torch.load('../models/encoder.m{0}'.format(2))\n",
    "# decoder2 = torch.load('../models/decoder.m{0}'.format(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Name error------------------------------!\n",
      "error: Name error------------------------------!\n"
     ]
    }
   ],
   "source": [
    "import dataProcess as dp\n",
    "inputlang = dp.Lang('en')\n",
    "outputlang = dp.Lang('zh')\n",
    "inputlang.load('../data/en_train.pkl')\n",
    "outputlang.load('../data/zh_train.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "do you think we look young enough to blend in at a high school ?\n",
      " 你 们 觉 得 我 们 看 起 来 够 年 轻 溜 进 高 中 吗 ？ \n",
      "en 8501\n",
      "zh 2956\n"
     ]
    }
   ],
   "source": [
    "import validDataProcess as vdp\n",
    "h5py_file = h5py.File('../data/valid_data.h5py','r')\n",
    "valid_pairs = h5py_file['pairs']\n",
    "print(len(valid_pairs))\n",
    "print(valid_pairs[0][0].decode('utf-8'))\n",
    "print(valid_pairs[0][1].decode('gb2312'))\n",
    "\n",
    "valid_inputlang = vdp.Lang('en')\n",
    "valid_outputlang = vdp.Lang('zh')\n",
    "valid_inputlang.load('../data/en_valid1.pkl')\n",
    "valid_outputlang.load('../data/zh_valid1.pkl')\n",
    "\n",
    "print(valid_inputlang.name,valid_inputlang.n_words)\n",
    "print(valid_outputlang.name,valid_outputlang.n_words)\n",
    "#h5py_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> many men think they are going to die brother . a few of us know it .\n",
      "=  神 父 ， 许 多 人 觉 得 他 们 会 死 。 但 只 有 少 数 人 知 道 他 们 什 么 时 候 会 死 。 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/liwb/Documents/projects/machineTranslation/code/models.py:62: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, hidden = self.gru(output, hidden)\n",
      "/data/liwb/Documents/projects/machineTranslation/code/models.py:140: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, hidden = self.gru(output, hidden)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<  他 们 知 道 ， 我 们 会 。         \n",
      "\n",
      "> so there s no shortage of people who know about his achilles heel .\n",
      "=  所 以 很 多 人 知 道 他 的 要 害 。 \n",
      "<  所 以 他 的 人 ， 不 知 道 ， 他 ，      \n",
      "\n",
      "> so what s it gonna be come and play with my begonias ?\n",
      "=  你 难 道 会 说 ， 来 亲 亲 我 的 秋 海 棠 吧 ？ \n",
      "<  所 以 我 们 的 什 么 ？            \n",
      "\n",
      "> drive the east toward london and toronto to exit norwich avenue .\n",
      "=  沿 着 4 0 1 号 高 速 公 路 东 段 朝 伦 敦 和 多 伦 多 行 驶 ， 在 诺 维 奇 大 道 2 3 2 号 出 口 下 高 速 。 \n",
      "<  在 的 的 中 国 人 ， ， ， ， ， ， ， ， ，              \n",
      "\n",
      "> you gonna take care of his kids huh after he s gone ?\n",
      "=  你 得 照 顾 他 的 孩 子 ， 我 是 说 在 干 掉 他 之 后 ？ \n",
      "<  你 还 是 个 人 ， 了 ， 他 ， 了 ， ？                    \n",
      "\n",
      "> i gotta get over to her house . i miss her .\n",
      "=  我 要 去 她 家 ， 我 想 她 了 。 \n",
      "<  我 去 看 看 她 去 了 。   \n",
      "\n",
      "> you are like some damn roller coaster ride you know that ?\n",
      "=  感 觉 就 像 坐 了 趟 过 山 车 ， 知 道 吗 ？ \n",
      "<  你 知 道 ， 这 些 了 ，                   \n",
      "\n",
      "> i d begun to think you got called up in the rapture or something .\n",
      "=  我 差 点 以 为 你 被 提 了 呢 。 \n",
      "<  我 也 能 找 到 一 个 ， ， ，   \n",
      "\n",
      "> and where did we go ? the dark side of the moon .\n",
      "=  我 们 去 哪 了 ？   月 球 背 面 。 \n",
      "<  我 们 走 了 ？ 我 们 走 了 。   \n",
      "\n",
      "> every night at nine the whole crew goes out to dinner\n",
      "=  每 天 晚 上 一 到 9 点 ， 这 所 有 的 人 都 会 出 去 吃 晚 饭 \n",
      "<  在 的 的 小 小 心 的 人 ， 在                          \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "reload(models)\n",
    "models.evaluateRandomly(encoder2,decoder2,inputlang,outputlang,valid_pairs,n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/liwb/Documents/projects/machineTranslation/code/models.py:62: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, hidden = self.gru(output, hidden)\n",
      "/data/liwb/Documents/projects/machineTranslation/code/models.py:140: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, hidden = self.gru(output, hidden)\n",
      "/data/liwb/anaconda3/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '妈', '从', '打', '折', '店', '里', '给', '我', '买', '过', '一', '个', '一', '样', '的', '。']\n",
      "['', '我', '的', '朋', '友', '在', '这', '儿', '，', '在', '这', '儿', '。', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "['你', '没', '睡', '啊', '。', '我', '正', '要', '给', '你', '留', '言', '，', '不', '过', '…', '…']\n",
      "['', '你', '真', '是', '个', '，', '.', '.', '.', '.', '.', '', '', '', '', '']\n",
      "['是', '的', '，', '我', '发', '誓', '。', '你', '从', '没', '进', '过', '监', '狱', '？']\n",
      "['', '你', '不', '是', '在', '我', '的', '了', '，', '你', '，', '，', '了', '，', '？', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "['他', '妈', '的', '开', '门', '！', '够', '了', '。', '够', '了', '。']\n",
      "['', '听', '着', '，', '的', '，', '，', '，', '，', '，', '了', '！', '，', '', '', '']\n",
      "['我', '母', '女', '待', '在', '一', '起', '也', '是', '件', '好', '事', '情', '。']\n",
      "['', '我', '想', '我', '会', '也', '能', '做', '到', '的', '。', '', '', '', '', '', '', '', '']\n",
      "['把', '模', '型', '从', '窗', '口', '扔', '出', '去', '看', '它', '是', '如', '何', '落', '地', '的', '。']\n",
      "['', '他', '们', '把', '它', '们', '的', '手', '术', '，', '在', '', '', '']\n",
      "['上', '月', '从', '西', '雅', '图', '搬', '过', '来', '…', '…', '无', '功', '，', '无', '过', '。']\n",
      "['', '别', '人', '，', '。', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "['所', '以', '呢', '，', '我', '们', '就', '帮', '忙', '把', '她', '的', '拖', '车', '给', '移', '过', '去', '。']\n",
      "['', '我', '们', '我', '的', '我', '的', '的']\n",
      "['有', '时', '间', '吗', '？', '-', '呃', '-', '哦', '。', '-', '有', '啊', '，', '嗯', '哼', '…', '…']\n",
      "['', '你', '好', '吗', '？', '你', '还', '是', '个', '。', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/liwb/anaconda3/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['是', '的', '。', '你', '为', '什', '么', '认', '为', '他', '是', '被', '一', '个', '叫', '做', '胡', '佛', '的', '人', '运', '作', '的', '呢', '？']\n",
      "['', '是', '啊', '。', '你', '为', '什', '么', '？', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "bleu_score is: 0.0005768926345152574\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "reload(models)\n",
    "bleu_score = models.calculateValidData_BLEU_Score(encoder2,decoder2,inputlang,outputlang,valid_pairs)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
