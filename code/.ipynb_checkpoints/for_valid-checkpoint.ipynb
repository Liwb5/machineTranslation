{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import nltk\n",
    "\n",
    "import pickle\n",
    "import jieba\n",
    "import h5py\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Name error------------------------------!\n",
      "error: Name error------------------------------!\n"
     ]
    }
   ],
   "source": [
    "import dataProcess as dp\n",
    "inputlang = dp.Lang('en')\n",
    "outputlang = dp.Lang('zh')\n",
    "inputlang.load('../data/en_train.pkl')\n",
    "outputlang.load('../data/zh_train.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models\n",
    "importlib.reload(models)\n",
    "modelName = '_paramssecond'\n",
    "n_iter = 240000\n",
    "# encoder2 = torch.load('../models/encoder{0}.m{1}'.format(modelName,n_iter))\n",
    "# decoder2 = torch.load('../models/decoder{0}.m{1}'.format(modelName,n_iter))    \n",
    "encoder2 = models.EncoderRNN(inputlang.n_words,256)\n",
    "decoder2 = models.AttnDecoderRNN(256, outputlang.n_words,1,dropout_p=0.1)\n",
    "if use_cuda:\n",
    "    encoder2.cuda()\n",
    "    decoder2.cuda()\n",
    "#print(len(encoder2.embedding.data))\n",
    "encoder2.load_state_dict(torch.load('../models/encoder{0}.m{1}'.format(modelName,n_iter)))\n",
    "decoder2.load_state_dict(torch.load('../models/decoder{0}.m{1}'.format(modelName,n_iter)))\n",
    "decoder2.dropout = nn.Dropout(0)\n",
    "# encoder2 = torch.load('../models/encoder.m{0}'.format(2))\n",
    "# decoder2 = torch.load('../models/decoder.m{0}'.format(2))\n",
    "#print(len(encoder2.embedding.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: Name error------------------------------!\n",
      "error: Name error------------------------------!\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load valid data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "do you think we look young enough to blend in at a high school ?\n",
      " 你 们 觉 得 我 们 看 起 来 够 年 轻 溜 进 高 中 吗 ？ \n",
      "en 8501\n",
      "zh 2956\n"
     ]
    }
   ],
   "source": [
    "import validDataProcess as vdp\n",
    "h5py_file = h5py.File('../data/valid_data.h5py','r')\n",
    "valid_pairs = h5py_file['pairs']\n",
    "print(len(valid_pairs))\n",
    "print(valid_pairs[0][0].decode('utf-8'))\n",
    "print(valid_pairs[0][1].decode('gb2312'))\n",
    "\n",
    "valid_inputlang = vdp.Lang('en')\n",
    "valid_outputlang = vdp.Lang('zh')\n",
    "valid_inputlang.load('../data/en_valid1.pkl')\n",
    "valid_outputlang.load('../data/zh_valid1.pkl')\n",
    "\n",
    "print(valid_inputlang.name,valid_inputlang.n_words)\n",
    "print(valid_outputlang.name,valid_outputlang.n_words)\n",
    "#h5py_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> resupply from earth can be two or three years away .\n",
      "=  地 球 的 补 给 可 能 要 迟 后 2 到 3 年 。 \n",
      "<  约                                                          \n",
      "\n",
      "> maybe you guys should spend a shift back here see what it s like .\n",
      "=  你 们 也 该 轮 流 坐 坐 ， 感 受 一 下 。 \n",
      "<  监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监 监\n",
      "\n",
      "> we re trapped against the sea ! caleb warn the north tents !\n",
      "=  我 们 被 海 洋 阻 隔 着 ！ 卡 尼 ， 通 知 北 营 ！ \n",
      "< \n",
      "\n",
      "> i m not wearing my glasses . i can t see anything anyway .\n",
      "=  我 没 带 眼 镜 。 反 正 我 什 么 都 看 不 到 。 \n",
      "<                                                            \n",
      "\n",
      "> now this is all i can spare without my husband noticing .\n",
      "=  为 了 不 引 起 我 丈 夫 的 注 意 现 在 我 只 能 凑 到 这 么 多 。 \n",
      "<                                                            \n",
      "\n",
      "> my stomach is killing me and i m sweating and my nodes are swollen .\n",
      "=  我 肚 子 痛 ， 还 出 汗 ， 淋 巴 腺 还 浮 肿 。 \n",
      "< \n",
      "\n",
      "> the not so little voice in pinky mccoy s head agreed .\n",
      "=  平 奇   麦 考 伊 脑 际 有 个 并 不 小 的 声 音 表 示 认 同 。 \n",
      "< \n",
      "\n",
      "> work or relax it s your choice in one of our non smoking guest rooms offering the best in comfort .\n",
      "=  您 可 以 选 择 在 我 们 最 为 舒 适 的 无 烟 客 房 内 办 公 或 放 松 。 \n",
      "<  监 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春 春\n",
      "\n",
      "> students must complete and pass each module to be eligible for the diploma in fashion design and marketing award .\n",
      "=  学 生 必 须 完 成 并 通 过 每 个 模 块 ， 以 有 资 格 授 予 时 尚 设 计 和 营 销 的 文 凭 。 \n",
      "<  乏 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟 熟\n",
      "\n",
      "> just the history with him is so terrible and i just \n",
      "=  只 是 我 跟 他 以 往 的 经 历 太 糟 了 ， 我 只 是   - \n",
      "< \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "importlib.reload(models)\n",
    "models.evaluateRandomly(encoder2,decoder2,inputlang,outputlang,valid_pairs,n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/liwb/Documents/projects/machineTranslation/code/models.py:62: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, hidden = self.gru(output, hidden)\n",
      "/data/liwb/Documents/projects/machineTranslation/code/models.py:140: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greately increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, hidden = self.gru(output, hidden)\n",
      "/data/liwb/anaconda3/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '妈', '从', '打', '折', '店', '里', '给', '我', '买', '过', '一', '个', '一', '样', '的', '。']\n",
      "['', '我', '的', '朋', '友', '在', '这', '儿', '，', '在', '这', '儿', '。', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "['你', '没', '睡', '啊', '。', '我', '正', '要', '给', '你', '留', '言', '，', '不', '过', '…', '…']\n",
      "['', '你', '真', '是', '个', '，', '.', '.', '.', '.', '.', '', '', '', '', '']\n",
      "['是', '的', '，', '我', '发', '誓', '。', '你', '从', '没', '进', '过', '监', '狱', '？']\n",
      "['', '你', '不', '是', '在', '我', '的', '了', '，', '你', '，', '，', '了', '，', '？', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "['他', '妈', '的', '开', '门', '！', '够', '了', '。', '够', '了', '。']\n",
      "['', '听', '着', '，', '的', '，', '，', '，', '，', '，', '了', '！', '，', '', '', '']\n",
      "['我', '母', '女', '待', '在', '一', '起', '也', '是', '件', '好', '事', '情', '。']\n",
      "['', '我', '想', '我', '会', '也', '能', '做', '到', '的', '。', '', '', '', '', '', '', '', '']\n",
      "['把', '模', '型', '从', '窗', '口', '扔', '出', '去', '看', '它', '是', '如', '何', '落', '地', '的', '。']\n",
      "['', '他', '们', '把', '它', '们', '的', '手', '术', '，', '在', '', '', '']\n",
      "['上', '月', '从', '西', '雅', '图', '搬', '过', '来', '…', '…', '无', '功', '，', '无', '过', '。']\n",
      "['', '别', '人', '，', '。', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "['所', '以', '呢', '，', '我', '们', '就', '帮', '忙', '把', '她', '的', '拖', '车', '给', '移', '过', '去', '。']\n",
      "['', '我', '们', '我', '的', '我', '的', '的']\n",
      "['有', '时', '间', '吗', '？', '-', '呃', '-', '哦', '。', '-', '有', '啊', '，', '嗯', '哼', '…', '…']\n",
      "['', '你', '好', '吗', '？', '你', '还', '是', '个', '。', '', '', '', '', '', '', '', '', '', '', '', '']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/liwb/anaconda3/lib/python3.5/site-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
      "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
      "BLEU scores might be undesirable; use SmoothingFunction().\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['是', '的', '。', '你', '为', '什', '么', '认', '为', '他', '是', '被', '一', '个', '叫', '做', '胡', '佛', '的', '人', '运', '作', '的', '呢', '？']\n",
      "['', '是', '啊', '。', '你', '为', '什', '么', '？', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '']\n",
      "bleu_score is: 0.0005768926345152574\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "reload(models)\n",
    "bleu_score = models.calculateValidData_BLEU_Score(encoder2,decoder2,inputlang,outputlang,valid_pairs)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
