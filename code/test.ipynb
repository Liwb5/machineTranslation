{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import jieba\n",
    "import h5py\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a pair of red crowned cranes have staked out their nesting territory\n",
      " 一 对 丹 顶 鹤 正 监 视 着 它 们 的 筑 巢 领 地 \n",
      "error: Name error------------------------------!\n",
      "error: Name error------------------------------!\n",
      "en 388091\n",
      "zh 6754\n"
     ]
    }
   ],
   "source": [
    "import dataProcess as dp\n",
    "h5py_file = h5py.File('../data/train_afterProcess.h5py','r')\n",
    "pairs = h5py_file['pairs']\n",
    "\n",
    "print(pairs[0][0].decode('utf-8'))\n",
    "print(pairs[0][1].decode('gb2312'))\n",
    "\n",
    "inputlang = dp.Lang('en')\n",
    "outputlang = dp.Lang('zh')\n",
    "inputlang.load('../data/en_train.pkl')\n",
    "outputlang.load('../data/zh_train.pkl')\n",
    "\n",
    "print(inputlang.name,inputlang.n_words)\n",
    "print(outputlang.name,outputlang.n_words)\n",
    "#h5py_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it ll be just like we planned .\n"
     ]
    }
   ],
   "source": [
    "print(pairs[90987][0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now if you ll just take a seat we can begin .\n",
      " 好 ， 请 坐 吧 ， 这 样 我 们 就 可 以 开 始 了 。 \n"
     ]
    }
   ],
   "source": [
    "pair = random.choice(pairs)\n",
    "print(pair[0].decode('utf-8'))\n",
    "print(pair[1].decode('gb2312'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tt = ['我是中国人'.encode('gb2312'),'sdfeow dsf df dsf '.encode('utf-8')]\n",
    "h5 = h5py.File('../data/test1.h5py','w')\n",
    "h5.create_dataset('pairs',data=tt,dtype = 'S400')\n",
    "h5.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = inputlang.word2count\n",
    "wordFreqLess10 = 0#保存词频小于某个阈值的词\n",
    "wordFreqMore100 = 0\n",
    "all_word_count=0\n",
    "print('input english word count:' , inputlang.n_words)\n",
    "for word in count:\n",
    "    all_word_count += count[word]\n",
    "    if count[word] <= 10:\n",
    "        wordFreqLess10 +=count[word]\n",
    "    if count[word] <= 10:\n",
    "        wordFreqMore100 +=1\n",
    "print('word count larger than 100:',inputlang.n_words - wordFreqMore100)\n",
    "print('word count Less than 10:',wordFreqLess10)\n",
    "print('rate of word count less than 10:', float(wordFreqLess10)/float(all_word_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## filter input language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdict = {'a':23,'b':2,'c':4}\n",
    "test2 = {1:'d',34:'f',22:'t'}\n",
    "print(test2)\n",
    "test2.pop(34)\n",
    "print(test2)\n",
    "a = testdict.copy()\n",
    "print(a)\n",
    "for word in testdict:\n",
    "    if testdict[word] < 3:\n",
    "        a.pop(word)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 匹配生僻字与非法字符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_rare_name(string):\n",
    "    pattern = re.compile(u\"[~!@#$%^&* ]\")\n",
    "    match = pattern.search(string)\n",
    "    if match:\n",
    "        return True\n",
    "    try:\n",
    "        string.encode(\"gb2312\")\n",
    "    except UnicodeEncodeError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def normalizeChinese(s):\n",
    "    try:\n",
    "        s.encode(\"gb2312\")\n",
    "    except UnicodeEncodeError:\n",
    "        return ' '\n",
    "    s = re.sub(r\"[~!@#$%^&* ]+\",r' ', s)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str1 = '我 是 @ 中 国 人 ， 我 # 不 才 囧 怪。'\n",
    "#str1 = 'I an # a boy'\n",
    "l = [normalizeChinese(s) for s in str1.split(' ')]\n",
    "print(l)\n",
    "tmp = ' '\n",
    "for s in str1.split(' '):\n",
    "    val = normalizeChinese(s)\n",
    "    tmp += val+' '\n",
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = re.search(r'.','I love FishC.com!')\n",
    "print(result.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = '我 是 @ 中 国 人 ， 我 # 不 囧 才 怪。'\n",
    "s = re.sub(r\"[~!@#$%^&* ]+\",r' ', s)\n",
    "print (s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from hyperboard import Agent\n",
    "\n",
    "agent = Agent(port=5100)\n",
    "#agent = Agent(address='172.18.216.69',port=5000)\n",
    "hyperparameters = {'test':0.1}\n",
    "name = agent.register(hyperparameters, 'loss')\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "MAX_LENGTH = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test filter data to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#返回词对应的下标\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    #return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "    result = []\n",
    "    all_lang_keys = lang.word2index.keys()\n",
    "    for word in sentence.split(' '):\n",
    "        if word in all_lang_keys:\n",
    "            result.append(lang.word2index[word])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test12 = 'a boy is watching tree.'\n",
    "test11 = indexesFromSentence(inputlang, test12)\n",
    "print(test11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testdict = {'a':1,'b':23,'c':4}\n",
    "keys = testdict.keys()\n",
    "list_result = []\n",
    "for word in ['a','f','c','d']:\n",
    "    if word in keys:\n",
    "        list_result.append(testdict[word])\n",
    "print(list_result)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
