{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 135842 sentence pairs\n",
      "Trimmed to 10853 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "fra 4489\n",
      "eng 2925\n",
      "['vous avez parfaitement raison .', 'you re totally right .']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "#这个类通过不断输入sentence，构建词与下标的对应（词典），方便制作one-hot。\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "\n",
    "\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s\",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[1].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        #这个n_layers==1其实就是只相当于一个cell，对一个input(单词)和上一个hidden state\n",
    "        #这里做了一个gru操作。n_layers大于1则是对同一个东西迭代多次，也许效果会好。\n",
    "        for i in range(self.n_layers):\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "        \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, n_layers=1, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_output, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)))\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        for i in range(self.n_layers):\n",
    "            output = F.relu(output)\n",
    "            output, hidden = self.gru(output, hidden)\n",
    "\n",
    "        output = F.log_softmax(self.out(output[0]))\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda()\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda()\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from hyperboard import Agent\n",
    "\n",
    "agent = Agent(address='172.18.216.69',port=5000)\n",
    "hyperparameters = {\n",
    "                    'learning_rate':0.3\n",
    "                    }\n",
    "name = agent.register(hyperparameters, 'loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    #input_variable已经在函数外变成了tensor了，tensor的元素是词的下标\n",
    "    input_length = input_variable.size()[0]#source sentence 的长度\n",
    "    target_length = target_variable.size()[0]#目标句子的长度\n",
    "    \n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))#max_length=10，也就是句子的最长长度，hidden_size是256，所以encoder_outputs是矩阵10X256\n",
    "    encoder_outputs = encoder_outputs.cuda() if use_cuda else encoder_outputs\n",
    "   \n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):#句子有多长就迭代多少次\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        #print('encoder_output:',encoder_output)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]#将每个词encoder的output记录下来\n",
    "        #print('encoder_output:',encoder_output[0][0])\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "    \n",
    "    decoder_hidden = encoder_hidden#encoder最后一层的hidden_state传给decoder作为decoder的第一个hidden_state\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "        \t#encoder_outputs作为decoder的输入，是为了改变attention。\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])#这两个变量是什么形式\n",
    "            decoder_input = target_variable[di]  # Teacher forcing这个是直接给答案，也就是一个单词，进入decoder里面再变成词向量\n",
    "\n",
    "    else:#这边是不直接给答案，而是每次output那里选择概率最大的作为下一个输入\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_output, encoder_outputs)\n",
    "            #\n",
    "            topv, topi = decoder_output.data.topk(1) \n",
    "            ni = topi[0][0]\n",
    "            \n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda() if use_cuda else decoder_input\n",
    "            \n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()#如何理解这一步反向梯度对encoder和decoder都有效\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "\t#考虑改成其他的优化器\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    #这里的training_pairs经过variableFromPair处理后，每个元素已经是一个tensor了，并且是单词所在的下标，为了可以和embedd匹配。\n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    #print(random.choice(training_pairs)[0].data)\n",
    "    #print('length of training_pairs: ',len(training_pairs))\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "        \n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        #print(loss)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            agent.append(name, iter, plot_loss_avg)\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 0s (- 2m 10s) (1 0%) 7.9850\n",
      "0m 0s (- 1m 56s) (2 0%) 7.9900\n",
      "0m 0s (- 1m 51s) (3 0%) 7.9144\n",
      "0m 0s (- 1m 44s) (4 0%) 7.8731\n",
      "0m 0s (- 1m 48s) (5 0%) 7.9075\n",
      "0m 0s (- 1m 45s) (6 0%) 7.9333\n",
      "0m 0s (- 1m 37s) (7 0%) 3.4348\n",
      "0m 0s (- 1m 34s) (8 0%) 3.9599\n",
      "0m 0s (- 1m 31s) (9 0%) 5.2024\n",
      "0m 0s (- 1m 28s) (10 1%) 7.7492\n",
      "0m 0s (- 1m 24s) (11 1%) 6.2057\n",
      "0m 0s (- 1m 21s) (12 1%) 7.6770\n",
      "0m 1s (- 1m 19s) (13 1%) 3.7941\n",
      "0m 1s (- 1m 18s) (14 1%) 3.4189\n",
      "0m 1s (- 1m 19s) (15 1%) 3.1042\n",
      "0m 1s (- 1m 18s) (16 1%) 7.6708\n",
      "0m 1s (- 1m 19s) (17 1%) 7.7827\n",
      "0m 1s (- 1m 18s) (18 1%) 3.2152\n",
      "0m 1s (- 1m 17s) (19 1%) 3.6520\n",
      "0m 1s (- 1m 18s) (20 2%) 7.6094\n",
      "0m 1s (- 1m 19s) (21 2%) 7.4708\n",
      "0m 1s (- 1m 20s) (22 2%) 7.6797\n",
      "0m 1s (- 1m 19s) (23 2%) 7.2267\n",
      "0m 1s (- 1m 19s) (24 2%) 3.5867\n",
      "0m 2s (- 1m 20s) (25 2%) 7.0049\n",
      "0m 2s (- 1m 19s) (26 2%) 3.1513\n",
      "0m 2s (- 1m 21s) (27 2%) 7.2846\n",
      "0m 2s (- 1m 21s) (28 2%) 7.0708\n",
      "0m 2s (- 1m 21s) (29 2%) 7.1828\n",
      "0m 2s (- 1m 21s) (30 3%) 6.8246\n",
      "0m 2s (- 1m 21s) (31 3%) 6.0492\n",
      "0m 2s (- 1m 22s) (32 3%) 6.6990\n",
      "0m 2s (- 1m 21s) (33 3%) 1.7076\n",
      "0m 2s (- 1m 20s) (34 3%) 2.0705\n",
      "0m 2s (- 1m 21s) (35 3%) 6.0570\n",
      "0m 3s (- 1m 21s) (36 3%) 1.9035\n",
      "0m 3s (- 1m 21s) (37 3%) 6.4055\n",
      "0m 3s (- 1m 21s) (38 3%) 3.4083\n",
      "0m 3s (- 1m 21s) (39 3%) 1.7380\n",
      "0m 3s (- 1m 20s) (40 4%) 3.8457\n",
      "0m 3s (- 1m 20s) (41 4%) 4.8266\n",
      "0m 3s (- 1m 20s) (42 4%) 5.4873\n",
      "0m 3s (- 1m 20s) (43 4%) 1.4583\n",
      "0m 3s (- 1m 20s) (44 4%) 6.5792\n",
      "0m 3s (- 1m 20s) (45 4%) 1.7023\n",
      "0m 3s (- 1m 20s) (46 4%) 1.4785\n",
      "0m 3s (- 1m 20s) (47 4%) 1.3940\n",
      "0m 4s (- 1m 20s) (48 4%) 5.7567\n",
      "0m 4s (- 1m 20s) (49 4%) 5.0695\n",
      "0m 4s (- 1m 21s) (50 5%) 6.0560\n",
      "0m 4s (- 1m 21s) (51 5%) 3.2014\n",
      "0m 4s (- 1m 20s) (52 5%) 3.6531\n",
      "0m 4s (- 1m 20s) (53 5%) 2.1135\n",
      "0m 4s (- 1m 20s) (54 5%) 3.2011\n",
      "0m 4s (- 1m 20s) (55 5%) 5.1643\n",
      "0m 4s (- 1m 19s) (56 5%) 5.3488\n",
      "0m 4s (- 1m 19s) (57 5%) 4.1626\n",
      "0m 4s (- 1m 19s) (58 5%) 4.2877\n",
      "0m 4s (- 1m 18s) (59 5%) 5.5432\n",
      "0m 5s (- 1m 18s) (60 6%) 2.3513\n",
      "0m 5s (- 1m 18s) (61 6%) 4.2843\n",
      "0m 5s (- 1m 18s) (62 6%) 4.4797\n",
      "0m 5s (- 1m 17s) (63 6%) 2.5681\n",
      "0m 5s (- 1m 17s) (64 6%) 3.0304\n",
      "0m 5s (- 1m 17s) (65 6%) 3.5899\n",
      "0m 5s (- 1m 17s) (66 6%) 3.7971\n",
      "0m 5s (- 1m 17s) (67 6%) 4.5461\n",
      "0m 5s (- 1m 17s) (68 6%) 2.9578\n",
      "0m 5s (- 1m 17s) (69 6%) 3.9659\n",
      "0m 5s (- 1m 16s) (70 7%) 2.2143\n",
      "0m 5s (- 1m 17s) (71 7%) 5.8591\n",
      "0m 5s (- 1m 17s) (72 7%) 4.2544\n",
      "0m 6s (- 1m 16s) (73 7%) 4.4270\n",
      "0m 6s (- 1m 16s) (74 7%) 2.3111\n",
      "0m 6s (- 1m 16s) (75 7%) 4.3351\n",
      "0m 6s (- 1m 16s) (76 7%) 3.8083\n",
      "0m 6s (- 1m 16s) (77 7%) 3.4352\n",
      "0m 6s (- 1m 17s) (78 7%) 4.8900\n",
      "0m 6s (- 1m 17s) (79 7%) 3.5454\n",
      "0m 6s (- 1m 17s) (80 8%) 5.2429\n",
      "0m 6s (- 1m 17s) (81 8%) 3.2073\n",
      "0m 6s (- 1m 17s) (82 8%) 3.0145\n",
      "0m 6s (- 1m 17s) (83 8%) 2.8730\n",
      "0m 7s (- 1m 17s) (84 8%) 3.6126\n",
      "0m 7s (- 1m 17s) (85 8%) 5.1643\n",
      "0m 7s (- 1m 16s) (86 8%) 3.2319\n",
      "0m 7s (- 1m 16s) (87 8%) 2.2698\n",
      "0m 7s (- 1m 16s) (88 8%) 3.7172\n",
      "0m 7s (- 1m 16s) (89 8%) 4.5789\n",
      "0m 7s (- 1m 16s) (90 9%) 2.6222\n",
      "0m 7s (- 1m 16s) (91 9%) 3.7293\n",
      "0m 7s (- 1m 15s) (92 9%) 4.4243\n",
      "0m 7s (- 1m 16s) (93 9%) 3.7416\n",
      "0m 7s (- 1m 15s) (94 9%) 5.4558\n",
      "0m 7s (- 1m 16s) (95 9%) 3.7084\n",
      "0m 8s (- 1m 16s) (96 9%) 4.2523\n",
      "0m 8s (- 1m 16s) (97 9%) 4.1227\n",
      "0m 8s (- 1m 16s) (98 9%) 2.9779\n",
      "0m 8s (- 1m 16s) (99 9%) 2.8955\n",
      "0m 8s (- 1m 16s) (100 10%) 5.1906\n",
      "0m 8s (- 1m 16s) (101 10%) 3.6062\n",
      "0m 8s (- 1m 16s) (102 10%) 3.1906\n",
      "0m 8s (- 1m 16s) (103 10%) 5.2280\n",
      "0m 8s (- 1m 16s) (104 10%) 4.5873\n",
      "0m 8s (- 1m 16s) (105 10%) 4.3323\n",
      "0m 9s (- 1m 16s) (106 10%) 4.8788\n",
      "0m 9s (- 1m 16s) (107 10%) 3.8936\n",
      "0m 9s (- 1m 16s) (108 10%) 4.1192\n",
      "0m 9s (- 1m 16s) (109 10%) 3.1748\n",
      "0m 9s (- 1m 16s) (110 11%) 4.6507\n",
      "0m 9s (- 1m 16s) (111 11%) 2.3685\n",
      "0m 9s (- 1m 16s) (112 11%) 3.4992\n",
      "0m 9s (- 1m 16s) (113 11%) 4.5419\n",
      "0m 9s (- 1m 16s) (114 11%) 4.3558\n",
      "0m 9s (- 1m 16s) (115 11%) 4.0703\n",
      "0m 10s (- 1m 16s) (116 11%) 3.4787\n",
      "0m 10s (- 1m 16s) (117 11%) 3.1756\n",
      "0m 10s (- 1m 16s) (118 11%) 2.4676\n",
      "0m 10s (- 1m 16s) (119 11%) 4.6635\n",
      "0m 10s (- 1m 16s) (120 12%) 2.7291\n",
      "0m 10s (- 1m 16s) (121 12%) 2.4123\n",
      "0m 10s (- 1m 16s) (122 12%) 3.6865\n",
      "0m 10s (- 1m 16s) (123 12%) 5.7212\n",
      "0m 10s (- 1m 16s) (124 12%) 3.2207\n",
      "0m 10s (- 1m 16s) (125 12%) 4.5931\n",
      "0m 11s (- 1m 16s) (126 12%) 3.8536\n",
      "0m 11s (- 1m 16s) (127 12%) 4.0052\n",
      "0m 11s (- 1m 16s) (128 12%) 4.6866\n",
      "0m 11s (- 1m 16s) (129 12%) 3.2520\n",
      "0m 11s (- 1m 16s) (130 13%) 2.9948\n",
      "0m 11s (- 1m 16s) (131 13%) 2.7607\n",
      "0m 11s (- 1m 16s) (132 13%) 4.2018\n",
      "0m 11s (- 1m 15s) (133 13%) 2.0115\n",
      "0m 11s (- 1m 15s) (134 13%) 2.7946\n",
      "0m 11s (- 1m 15s) (135 13%) 3.1227\n",
      "0m 11s (- 1m 15s) (136 13%) 3.1507\n",
      "0m 12s (- 1m 15s) (137 13%) 3.0978\n",
      "0m 12s (- 1m 15s) (138 13%) 2.4460\n",
      "0m 12s (- 1m 15s) (139 13%) 4.0173\n",
      "0m 12s (- 1m 15s) (140 14%) 3.1129\n",
      "0m 12s (- 1m 15s) (141 14%) 2.7156\n",
      "0m 12s (- 1m 15s) (142 14%) 3.2278\n",
      "0m 12s (- 1m 15s) (143 14%) 2.6520\n",
      "0m 12s (- 1m 15s) (144 14%) 5.1772\n",
      "0m 12s (- 1m 15s) (145 14%) 2.6867\n",
      "0m 12s (- 1m 15s) (146 14%) 4.7179\n",
      "0m 12s (- 1m 15s) (147 14%) 3.4635\n",
      "0m 13s (- 1m 15s) (148 14%) 3.0524\n",
      "0m 13s (- 1m 14s) (149 14%) 2.0759\n",
      "0m 13s (- 1m 15s) (150 15%) 5.2192\n",
      "0m 13s (- 1m 15s) (151 15%) 3.7050\n",
      "0m 13s (- 1m 14s) (152 15%) 2.9415\n",
      "0m 13s (- 1m 14s) (153 15%) 3.8741\n",
      "0m 13s (- 1m 14s) (154 15%) 3.9234\n",
      "0m 13s (- 1m 14s) (155 15%) 3.9580\n",
      "0m 13s (- 1m 14s) (156 15%) 3.1254\n",
      "0m 13s (- 1m 14s) (157 15%) 3.4892\n",
      "0m 13s (- 1m 13s) (158 15%) 2.2157\n",
      "0m 13s (- 1m 13s) (159 15%) 4.1185\n",
      "0m 14s (- 1m 13s) (160 16%) 3.9316\n",
      "0m 14s (- 1m 13s) (161 16%) 2.0864\n",
      "0m 14s (- 1m 13s) (162 16%) 3.6013\n",
      "0m 14s (- 1m 13s) (163 16%) 3.4648\n",
      "0m 14s (- 1m 13s) (164 16%) 4.5730\n",
      "0m 14s (- 1m 13s) (165 16%) 2.3283\n",
      "0m 14s (- 1m 12s) (166 16%) 2.7781\n",
      "0m 14s (- 1m 12s) (167 16%) 3.0951\n",
      "0m 14s (- 1m 12s) (168 16%) 4.7420\n",
      "0m 14s (- 1m 12s) (169 16%) 3.7738\n",
      "0m 14s (- 1m 12s) (170 17%) 3.6915\n",
      "0m 14s (- 1m 12s) (171 17%) 3.9247\n",
      "0m 15s (- 1m 12s) (172 17%) 4.3988\n",
      "0m 15s (- 1m 12s) (173 17%) 3.3141\n",
      "0m 15s (- 1m 12s) (174 17%) 3.3867\n",
      "0m 15s (- 1m 12s) (175 17%) 2.3266\n",
      "0m 15s (- 1m 12s) (176 17%) 4.2687\n",
      "0m 15s (- 1m 12s) (177 17%) 5.3098\n",
      "0m 15s (- 1m 12s) (178 17%) 2.5295\n",
      "0m 15s (- 1m 12s) (179 17%) 4.9202\n",
      "0m 15s (- 1m 11s) (180 18%) 4.2869\n",
      "0m 15s (- 1m 11s) (181 18%) 2.4582\n",
      "0m 15s (- 1m 11s) (182 18%) 3.0655\n",
      "0m 15s (- 1m 11s) (183 18%) 3.2945\n",
      "0m 16s (- 1m 11s) (184 18%) 3.2691\n",
      "0m 16s (- 1m 11s) (185 18%) 4.0310\n",
      "0m 16s (- 1m 11s) (186 18%) 5.7996\n",
      "0m 16s (- 1m 11s) (187 18%) 3.4858\n",
      "0m 16s (- 1m 10s) (188 18%) 3.1435\n",
      "0m 16s (- 1m 10s) (189 18%) 3.9423\n",
      "0m 16s (- 1m 10s) (190 19%) 2.2154\n",
      "0m 16s (- 1m 10s) (191 19%) 2.7994\n",
      "0m 16s (- 1m 10s) (192 19%) 6.1172\n",
      "0m 16s (- 1m 10s) (193 19%) 3.2093\n",
      "0m 16s (- 1m 10s) (194 19%) 2.2172\n",
      "0m 16s (- 1m 9s) (195 19%) 3.4198\n",
      "0m 17s (- 1m 9s) (196 19%) 2.7323\n",
      "0m 17s (- 1m 9s) (197 19%) 1.4787\n",
      "0m 17s (- 1m 9s) (198 19%) 2.8089\n",
      "0m 17s (- 1m 9s) (199 19%) 2.8393\n",
      "0m 17s (- 1m 9s) (200 20%) 4.2953\n",
      "0m 17s (- 1m 9s) (201 20%) 3.6799\n",
      "0m 17s (- 1m 9s) (202 20%) 3.6539\n",
      "0m 17s (- 1m 8s) (203 20%) 3.0295\n",
      "0m 17s (- 1m 8s) (204 20%) 2.3339\n",
      "0m 17s (- 1m 8s) (205 20%) 3.9904\n",
      "0m 17s (- 1m 8s) (206 20%) 2.5069\n",
      "0m 17s (- 1m 8s) (207 20%) 2.8745\n",
      "0m 17s (- 1m 8s) (208 20%) 1.1064\n",
      "0m 17s (- 1m 8s) (209 20%) 3.7015\n",
      "0m 18s (- 1m 7s) (210 21%) 1.6765\n",
      "0m 18s (- 1m 7s) (211 21%) 3.9541\n",
      "0m 18s (- 1m 7s) (212 21%) 4.1074\n",
      "0m 18s (- 1m 7s) (213 21%) 3.3020\n",
      "0m 18s (- 1m 7s) (214 21%) 3.4301\n",
      "0m 18s (- 1m 7s) (215 21%) 3.6637\n",
      "0m 18s (- 1m 7s) (216 21%) 4.4179\n",
      "0m 18s (- 1m 6s) (217 21%) 3.8651\n",
      "0m 18s (- 1m 6s) (218 21%) 5.0532\n",
      "0m 18s (- 1m 6s) (219 21%) 3.0918\n",
      "0m 18s (- 1m 6s) (220 22%) 3.2692\n",
      "0m 19s (- 1m 7s) (221 22%) 3.4431\n",
      "0m 19s (- 1m 7s) (222 22%) 3.6960\n",
      "0m 19s (- 1m 7s) (223 22%) 4.2903\n",
      "0m 19s (- 1m 7s) (224 22%) 3.9799\n",
      "0m 19s (- 1m 7s) (225 22%) 3.9656\n",
      "0m 19s (- 1m 7s) (226 22%) 3.3924\n",
      "0m 19s (- 1m 7s) (227 22%) 3.7967\n",
      "0m 19s (- 1m 7s) (228 22%) 2.7543\n",
      "0m 19s (- 1m 7s) (229 22%) 2.9541\n",
      "0m 20s (- 1m 7s) (230 23%) 4.4919\n",
      "0m 20s (- 1m 7s) (231 23%) 2.7264\n",
      "0m 20s (- 1m 6s) (232 23%) 3.6835\n",
      "0m 20s (- 1m 6s) (233 23%) 4.0955\n",
      "0m 20s (- 1m 6s) (234 23%) 3.9419\n",
      "0m 20s (- 1m 6s) (235 23%) 3.7410\n",
      "0m 20s (- 1m 6s) (236 23%) 3.8443\n",
      "0m 20s (- 1m 6s) (237 23%) 4.3846\n",
      "0m 20s (- 1m 6s) (238 23%) 2.7979\n",
      "0m 20s (- 1m 6s) (239 23%) 3.4859\n",
      "0m 20s (- 1m 5s) (240 24%) 2.9035\n",
      "0m 20s (- 1m 5s) (241 24%) 3.3280\n",
      "0m 20s (- 1m 5s) (242 24%) 3.6364\n",
      "0m 21s (- 1m 5s) (243 24%) 2.7144\n",
      "0m 21s (- 1m 5s) (244 24%) 2.5972\n",
      "0m 21s (- 1m 5s) (245 24%) 3.7586\n",
      "0m 21s (- 1m 5s) (246 24%) 2.7005\n",
      "0m 21s (- 1m 5s) (247 24%) 4.4030\n",
      "0m 21s (- 1m 4s) (248 24%) 3.3600\n",
      "0m 21s (- 1m 5s) (249 24%) 4.8425\n",
      "0m 21s (- 1m 4s) (250 25%) 2.9231\n",
      "0m 21s (- 1m 4s) (251 25%) 1.3007\n",
      "0m 21s (- 1m 4s) (252 25%) 3.9478\n",
      "0m 21s (- 1m 4s) (253 25%) 3.5448\n",
      "0m 21s (- 1m 4s) (254 25%) 5.6822\n",
      "0m 22s (- 1m 4s) (255 25%) 3.8190\n",
      "0m 22s (- 1m 4s) (256 25%) 2.3881\n",
      "0m 22s (- 1m 4s) (257 25%) 3.3036\n",
      "0m 22s (- 1m 4s) (258 25%) 5.1432\n",
      "0m 22s (- 1m 3s) (259 25%) 2.8857\n",
      "0m 22s (- 1m 3s) (260 26%) 2.3156\n",
      "0m 22s (- 1m 3s) (261 26%) 2.8648\n",
      "0m 22s (- 1m 3s) (262 26%) 2.5763\n",
      "0m 22s (- 1m 3s) (263 26%) 3.6651\n",
      "0m 22s (- 1m 3s) (264 26%) 3.1680\n",
      "0m 22s (- 1m 3s) (265 26%) 3.0252\n",
      "0m 22s (- 1m 3s) (266 26%) 2.2741\n",
      "0m 23s (- 1m 3s) (267 26%) 2.5768\n",
      "0m 23s (- 1m 3s) (268 26%) 3.2027\n",
      "0m 23s (- 1m 3s) (269 26%) 4.8350\n",
      "0m 23s (- 1m 3s) (270 27%) 3.7487\n",
      "0m 23s (- 1m 3s) (271 27%) 4.4488\n",
      "0m 23s (- 1m 2s) (272 27%) 4.4327\n",
      "0m 23s (- 1m 2s) (273 27%) 3.0764\n",
      "0m 23s (- 1m 2s) (274 27%) 3.4122\n",
      "0m 23s (- 1m 2s) (275 27%) 3.0495\n",
      "0m 23s (- 1m 2s) (276 27%) 3.3418\n",
      "0m 23s (- 1m 2s) (277 27%) 3.7673\n",
      "0m 23s (- 1m 2s) (278 27%) 3.4483\n",
      "0m 24s (- 1m 2s) (279 27%) 3.3565\n",
      "0m 24s (- 1m 2s) (280 28%) 2.9898\n",
      "0m 24s (- 1m 1s) (281 28%) 2.4354\n",
      "0m 24s (- 1m 1s) (282 28%) 3.7100\n",
      "0m 24s (- 1m 1s) (283 28%) 3.1336\n",
      "0m 24s (- 1m 1s) (284 28%) 2.0227\n",
      "0m 24s (- 1m 1s) (285 28%) 3.9712\n",
      "0m 24s (- 1m 1s) (286 28%) 5.0635\n",
      "0m 24s (- 1m 1s) (287 28%) 3.4181\n",
      "0m 24s (- 1m 1s) (288 28%) 3.7316\n",
      "0m 24s (- 1m 1s) (289 28%) 3.6619\n",
      "0m 25s (- 1m 1s) (290 28%) 3.8762\n",
      "0m 25s (- 1m 1s) (291 29%) 2.4608\n",
      "0m 25s (- 1m 1s) (292 29%) 4.4051\n",
      "0m 25s (- 1m 1s) (293 29%) 3.9325\n",
      "0m 25s (- 1m 1s) (294 29%) 4.7905\n",
      "0m 25s (- 1m 1s) (295 29%) 4.4377\n",
      "0m 25s (- 1m 1s) (296 29%) 2.8620\n",
      "0m 25s (- 1m 0s) (297 29%) 3.3255\n",
      "0m 25s (- 1m 0s) (298 29%) 4.7931\n",
      "0m 25s (- 1m 0s) (299 29%) 3.6590\n",
      "0m 25s (- 1m 0s) (300 30%) 2.5195\n",
      "0m 26s (- 1m 0s) (301 30%) 3.7339\n",
      "0m 26s (- 1m 0s) (302 30%) 3.6521\n",
      "0m 26s (- 1m 0s) (303 30%) 3.2995\n",
      "0m 26s (- 1m 0s) (304 30%) 1.9031\n",
      "0m 26s (- 1m 0s) (305 30%) 3.4118\n",
      "0m 26s (- 1m 0s) (306 30%) 3.5452\n",
      "0m 26s (- 1m 0s) (307 30%) 2.7467\n",
      "0m 26s (- 0m 59s) (308 30%) 3.7073\n",
      "0m 26s (- 0m 59s) (309 30%) 3.2285\n",
      "0m 26s (- 0m 59s) (310 31%) 3.1349\n",
      "0m 26s (- 0m 59s) (311 31%) 2.1867\n",
      "0m 26s (- 0m 59s) (312 31%) 2.4694\n",
      "0m 27s (- 0m 59s) (313 31%) 2.4541\n",
      "0m 27s (- 0m 59s) (314 31%) 2.9239\n",
      "0m 27s (- 0m 59s) (315 31%) 4.3518\n",
      "0m 27s (- 0m 59s) (316 31%) 2.7749\n",
      "0m 27s (- 0m 59s) (317 31%) 2.9762\n",
      "0m 27s (- 0m 58s) (318 31%) 2.2484\n",
      "0m 27s (- 0m 58s) (319 31%) 2.8478\n",
      "0m 27s (- 0m 58s) (320 32%) 3.5550\n",
      "0m 27s (- 0m 58s) (321 32%) 4.1047\n",
      "0m 27s (- 0m 58s) (322 32%) 3.6582\n",
      "0m 27s (- 0m 58s) (323 32%) 2.1919\n",
      "0m 27s (- 0m 58s) (324 32%) 2.7358\n",
      "0m 27s (- 0m 58s) (325 32%) 2.6408\n",
      "0m 28s (- 0m 57s) (326 32%) 3.9609\n",
      "0m 28s (- 0m 57s) (327 32%) 2.8322\n",
      "0m 28s (- 0m 57s) (328 32%) 3.2774\n",
      "0m 28s (- 0m 57s) (329 32%) 3.2490\n",
      "0m 28s (- 0m 57s) (330 33%) 3.6178\n",
      "0m 28s (- 0m 57s) (331 33%) 3.3818\n",
      "0m 28s (- 0m 57s) (332 33%) 3.0626\n",
      "0m 28s (- 0m 57s) (333 33%) 4.2975\n",
      "0m 28s (- 0m 57s) (334 33%) 3.5579\n",
      "0m 28s (- 0m 57s) (335 33%) 3.0689\n",
      "0m 28s (- 0m 56s) (336 33%) 2.2339\n",
      "0m 28s (- 0m 56s) (337 33%) 3.4515\n",
      "0m 28s (- 0m 56s) (338 33%) 3.7984\n",
      "0m 29s (- 0m 56s) (339 33%) 3.2608\n",
      "0m 29s (- 0m 56s) (340 34%) 3.0456\n",
      "0m 29s (- 0m 56s) (341 34%) 3.2483\n",
      "0m 29s (- 0m 56s) (342 34%) 2.0207\n",
      "0m 29s (- 0m 56s) (343 34%) 3.6041\n",
      "0m 29s (- 0m 56s) (344 34%) 3.1867\n",
      "0m 29s (- 0m 56s) (345 34%) 3.4441\n",
      "0m 29s (- 0m 55s) (346 34%) 2.5873\n",
      "0m 29s (- 0m 55s) (347 34%) 2.5238\n",
      "0m 29s (- 0m 55s) (348 34%) 3.8518\n",
      "0m 29s (- 0m 55s) (349 34%) 3.9306\n",
      "0m 29s (- 0m 55s) (350 35%) 3.2388\n",
      "0m 29s (- 0m 55s) (351 35%) 2.6217\n",
      "0m 30s (- 0m 55s) (352 35%) 5.5598\n",
      "0m 30s (- 0m 55s) (353 35%) 3.4530\n",
      "0m 30s (- 0m 55s) (354 35%) 2.9125\n",
      "0m 30s (- 0m 55s) (355 35%) 2.6524\n",
      "0m 30s (- 0m 54s) (356 35%) 2.8168\n",
      "0m 30s (- 0m 54s) (357 35%) 3.3164\n",
      "0m 30s (- 0m 54s) (358 35%) 2.3299\n",
      "0m 30s (- 0m 54s) (359 35%) 3.2417\n",
      "0m 30s (- 0m 54s) (360 36%) 2.1351\n",
      "0m 30s (- 0m 54s) (361 36%) 2.3818\n",
      "0m 30s (- 0m 54s) (362 36%) 3.0941\n",
      "0m 30s (- 0m 54s) (363 36%) 2.9465\n",
      "0m 30s (- 0m 53s) (364 36%) 2.1441\n",
      "0m 30s (- 0m 53s) (365 36%) 3.1473\n",
      "0m 31s (- 0m 53s) (366 36%) 2.7483\n",
      "0m 31s (- 0m 53s) (367 36%) 3.1613\n",
      "0m 31s (- 0m 53s) (368 36%) 5.2831\n",
      "0m 31s (- 0m 53s) (369 36%) 4.1841\n",
      "0m 31s (- 0m 53s) (370 37%) 2.6628\n",
      "0m 31s (- 0m 53s) (371 37%) 3.9862\n",
      "0m 31s (- 0m 53s) (372 37%) 2.8569\n",
      "0m 31s (- 0m 53s) (373 37%) 2.6235\n",
      "0m 31s (- 0m 52s) (374 37%) 2.3396\n",
      "0m 31s (- 0m 52s) (375 37%) 2.3556\n",
      "0m 31s (- 0m 52s) (376 37%) 5.2873\n",
      "0m 31s (- 0m 52s) (377 37%) 3.7188\n",
      "0m 31s (- 0m 52s) (378 37%) 3.5421\n",
      "0m 32s (- 0m 52s) (379 37%) 4.1466\n",
      "0m 32s (- 0m 52s) (380 38%) 3.3240\n",
      "0m 32s (- 0m 52s) (381 38%) 2.6735\n",
      "0m 32s (- 0m 52s) (382 38%) 2.9650\n",
      "0m 32s (- 0m 52s) (383 38%) 4.2331\n",
      "0m 32s (- 0m 52s) (384 38%) 3.1735\n",
      "0m 32s (- 0m 51s) (385 38%) 3.3626\n",
      "0m 32s (- 0m 51s) (386 38%) 3.1643\n",
      "0m 32s (- 0m 51s) (387 38%) 3.6719\n",
      "0m 32s (- 0m 51s) (388 38%) 3.9264\n",
      "0m 32s (- 0m 51s) (389 38%) 3.6133\n",
      "0m 32s (- 0m 51s) (390 39%) 3.1967\n",
      "0m 32s (- 0m 51s) (391 39%) 3.8125\n",
      "0m 33s (- 0m 51s) (392 39%) 2.7562\n",
      "0m 33s (- 0m 51s) (393 39%) 3.2343\n",
      "0m 33s (- 0m 51s) (394 39%) 3.9067\n",
      "0m 33s (- 0m 50s) (395 39%) 3.4723\n",
      "0m 33s (- 0m 50s) (396 39%) 2.9469\n",
      "0m 33s (- 0m 50s) (397 39%) 5.5514\n",
      "0m 33s (- 0m 50s) (398 39%) 3.4924\n",
      "0m 33s (- 0m 50s) (399 39%) 2.8966\n",
      "0m 33s (- 0m 50s) (400 40%) 2.4705\n",
      "0m 33s (- 0m 50s) (401 40%) 3.1788\n",
      "0m 33s (- 0m 50s) (402 40%) 2.5558\n",
      "0m 33s (- 0m 50s) (403 40%) 3.4003\n",
      "0m 33s (- 0m 50s) (404 40%) 4.2277\n",
      "0m 34s (- 0m 50s) (405 40%) 2.9878\n",
      "0m 34s (- 0m 49s) (406 40%) 4.4922\n",
      "0m 34s (- 0m 49s) (407 40%) 3.0793\n",
      "0m 34s (- 0m 49s) (408 40%) 3.7396\n",
      "0m 34s (- 0m 49s) (409 40%) 3.5198\n",
      "0m 34s (- 0m 49s) (410 41%) 3.2265\n",
      "0m 34s (- 0m 49s) (411 41%) 2.7402\n",
      "0m 34s (- 0m 49s) (412 41%) 3.9116\n",
      "0m 34s (- 0m 49s) (413 41%) 5.1650\n",
      "0m 34s (- 0m 49s) (414 41%) 2.4205\n",
      "0m 34s (- 0m 49s) (415 41%) 3.3759\n",
      "0m 35s (- 0m 49s) (416 41%) 4.1332\n",
      "0m 35s (- 0m 49s) (417 41%) 3.4752\n",
      "0m 35s (- 0m 49s) (418 41%) 4.8655\n",
      "0m 35s (- 0m 49s) (419 41%) 3.9430\n",
      "0m 35s (- 0m 49s) (420 42%) 2.5159\n",
      "0m 35s (- 0m 48s) (421 42%) 3.0984\n",
      "0m 35s (- 0m 48s) (422 42%) 3.6319\n",
      "0m 35s (- 0m 48s) (423 42%) 3.2937\n",
      "0m 35s (- 0m 48s) (424 42%) 3.2227\n",
      "0m 35s (- 0m 48s) (425 42%) 3.3463\n",
      "0m 36s (- 0m 48s) (426 42%) 2.6768\n",
      "0m 36s (- 0m 48s) (427 42%) 3.5912\n",
      "0m 36s (- 0m 48s) (428 42%) 2.6532\n",
      "0m 36s (- 0m 48s) (429 42%) 4.7423\n",
      "0m 36s (- 0m 48s) (430 43%) 3.2359\n",
      "0m 36s (- 0m 48s) (431 43%) 2.6566\n",
      "0m 36s (- 0m 48s) (432 43%) 1.9256\n",
      "0m 36s (- 0m 48s) (433 43%) 3.9673\n",
      "0m 36s (- 0m 47s) (434 43%) 3.6471\n",
      "0m 36s (- 0m 47s) (435 43%) 4.3627\n",
      "0m 36s (- 0m 47s) (436 43%) 4.0392\n",
      "0m 37s (- 0m 47s) (437 43%) 3.1470\n",
      "0m 37s (- 0m 47s) (438 43%) 4.5857\n",
      "0m 37s (- 0m 47s) (439 43%) 4.4083\n",
      "0m 37s (- 0m 47s) (440 44%) 3.2662\n",
      "0m 37s (- 0m 47s) (441 44%) 3.9470\n",
      "0m 37s (- 0m 47s) (442 44%) 3.3590\n",
      "0m 37s (- 0m 47s) (443 44%) 2.2130\n",
      "0m 37s (- 0m 47s) (444 44%) 2.2224\n",
      "0m 37s (- 0m 47s) (445 44%) 3.6075\n",
      "0m 37s (- 0m 46s) (446 44%) 2.6311\n",
      "0m 37s (- 0m 46s) (447 44%) 3.7260\n",
      "0m 37s (- 0m 46s) (448 44%) 3.4372\n",
      "0m 37s (- 0m 46s) (449 44%) 2.5499\n",
      "0m 38s (- 0m 46s) (450 45%) 2.9799\n",
      "0m 38s (- 0m 46s) (451 45%) 3.9891\n",
      "0m 38s (- 0m 46s) (452 45%) 3.1878\n",
      "0m 38s (- 0m 46s) (453 45%) 3.6678\n",
      "0m 38s (- 0m 46s) (454 45%) 4.8476\n",
      "0m 38s (- 0m 46s) (455 45%) 5.0055\n",
      "0m 38s (- 0m 46s) (456 45%) 2.8763\n",
      "0m 38s (- 0m 45s) (457 45%) 3.8686\n",
      "0m 38s (- 0m 45s) (458 45%) 3.3087\n",
      "0m 38s (- 0m 45s) (459 45%) 2.3428\n",
      "0m 39s (- 0m 45s) (460 46%) 4.3603\n",
      "0m 39s (- 0m 45s) (461 46%) 3.0932\n",
      "0m 39s (- 0m 45s) (462 46%) 3.2628\n",
      "0m 39s (- 0m 45s) (463 46%) 3.0795\n",
      "0m 39s (- 0m 45s) (464 46%) 3.8299\n",
      "0m 39s (- 0m 45s) (465 46%) 2.4377\n",
      "0m 39s (- 0m 45s) (466 46%) 2.2026\n",
      "0m 39s (- 0m 45s) (467 46%) 2.0139\n",
      "0m 39s (- 0m 45s) (468 46%) 2.7335\n",
      "0m 39s (- 0m 45s) (469 46%) 4.2573\n",
      "0m 39s (- 0m 45s) (470 47%) 4.3509\n",
      "0m 40s (- 0m 44s) (471 47%) 2.8837\n",
      "0m 40s (- 0m 44s) (472 47%) 3.5140\n",
      "0m 40s (- 0m 44s) (473 47%) 5.0700\n",
      "0m 40s (- 0m 44s) (474 47%) 2.5703\n",
      "0m 40s (- 0m 44s) (475 47%) 2.8770\n",
      "0m 40s (- 0m 44s) (476 47%) 2.5537\n",
      "0m 40s (- 0m 44s) (477 47%) 3.8834\n",
      "0m 40s (- 0m 44s) (478 47%) 3.5964\n",
      "0m 40s (- 0m 44s) (479 47%) 4.0556\n",
      "0m 40s (- 0m 44s) (480 48%) 2.8559\n",
      "0m 40s (- 0m 44s) (481 48%) 3.1347\n",
      "0m 41s (- 0m 44s) (482 48%) 2.3281\n",
      "0m 41s (- 0m 44s) (483 48%) 4.2086\n",
      "0m 41s (- 0m 43s) (484 48%) 2.8533\n",
      "0m 41s (- 0m 43s) (485 48%) 2.2756\n",
      "0m 41s (- 0m 43s) (486 48%) 3.3970\n",
      "0m 41s (- 0m 43s) (487 48%) 2.7586\n",
      "0m 41s (- 0m 43s) (488 48%) 3.0753\n",
      "0m 41s (- 0m 43s) (489 48%) 3.2008\n",
      "0m 41s (- 0m 43s) (490 49%) 2.5940\n",
      "0m 41s (- 0m 43s) (491 49%) 2.9871\n",
      "0m 41s (- 0m 43s) (492 49%) 5.3182\n",
      "0m 41s (- 0m 43s) (493 49%) 3.9416\n",
      "0m 42s (- 0m 43s) (494 49%) 3.6362\n",
      "0m 42s (- 0m 42s) (495 49%) 3.6814\n",
      "0m 42s (- 0m 42s) (496 49%) 4.2759\n",
      "0m 42s (- 0m 42s) (497 49%) 4.2422\n",
      "0m 42s (- 0m 42s) (498 49%) 4.3263\n",
      "0m 42s (- 0m 42s) (499 49%) 3.6160\n",
      "0m 42s (- 0m 42s) (500 50%) 4.5658\n",
      "0m 42s (- 0m 42s) (501 50%) 3.8641\n",
      "0m 42s (- 0m 42s) (502 50%) 3.6089\n",
      "0m 42s (- 0m 42s) (503 50%) 2.9130\n",
      "0m 42s (- 0m 42s) (504 50%) 3.5611\n",
      "0m 42s (- 0m 42s) (505 50%) 2.2060\n",
      "0m 43s (- 0m 41s) (506 50%) 2.6298\n",
      "0m 43s (- 0m 41s) (507 50%) 2.9997\n",
      "0m 43s (- 0m 41s) (508 50%) 2.7222\n",
      "0m 43s (- 0m 41s) (509 50%) 3.9607\n",
      "0m 43s (- 0m 41s) (510 51%) 4.1542\n",
      "0m 43s (- 0m 41s) (511 51%) 4.9998\n",
      "0m 43s (- 0m 41s) (512 51%) 3.1993\n",
      "0m 43s (- 0m 41s) (513 51%) 5.0243\n",
      "0m 43s (- 0m 41s) (514 51%) 3.6584\n",
      "0m 43s (- 0m 41s) (515 51%) 3.1510\n",
      "0m 43s (- 0m 41s) (516 51%) 2.8318\n",
      "0m 43s (- 0m 40s) (517 51%) 2.3096\n",
      "0m 43s (- 0m 40s) (518 51%) 2.8393\n",
      "0m 44s (- 0m 40s) (519 51%) 3.6877\n",
      "0m 44s (- 0m 40s) (520 52%) 2.8166\n",
      "0m 44s (- 0m 40s) (521 52%) 4.5378\n",
      "0m 44s (- 0m 40s) (522 52%) 4.6677\n",
      "0m 44s (- 0m 40s) (523 52%) 3.6365\n",
      "0m 44s (- 0m 40s) (524 52%) 3.7440\n",
      "0m 44s (- 0m 40s) (525 52%) 3.6293\n",
      "0m 44s (- 0m 40s) (526 52%) 2.7435\n",
      "0m 44s (- 0m 40s) (527 52%) 4.0150\n",
      "0m 44s (- 0m 40s) (528 52%) 4.2205\n",
      "0m 44s (- 0m 39s) (529 52%) 3.0079\n",
      "0m 44s (- 0m 39s) (530 53%) 3.7540\n",
      "0m 45s (- 0m 39s) (531 53%) 3.2443\n",
      "0m 45s (- 0m 39s) (532 53%) 2.3555\n",
      "0m 45s (- 0m 39s) (533 53%) 2.6100\n",
      "0m 45s (- 0m 39s) (534 53%) 2.5041\n",
      "0m 45s (- 0m 39s) (535 53%) 2.8219\n",
      "0m 45s (- 0m 39s) (536 53%) 3.5930\n",
      "0m 45s (- 0m 39s) (537 53%) 3.6567\n",
      "0m 45s (- 0m 39s) (538 53%) 3.7187\n",
      "0m 45s (- 0m 39s) (539 53%) 3.2955\n",
      "0m 45s (- 0m 39s) (540 54%) 2.8413\n",
      "0m 46s (- 0m 39s) (541 54%) 3.4010\n",
      "0m 46s (- 0m 39s) (542 54%) 3.1444\n",
      "0m 46s (- 0m 38s) (543 54%) 4.0516\n",
      "0m 46s (- 0m 38s) (544 54%) 2.7206\n",
      "0m 46s (- 0m 38s) (545 54%) 2.6121\n",
      "0m 46s (- 0m 38s) (546 54%) 4.0513\n",
      "0m 46s (- 0m 38s) (547 54%) 3.0252\n",
      "0m 46s (- 0m 38s) (548 54%) 2.5280\n",
      "0m 46s (- 0m 38s) (549 54%) 3.2267\n",
      "0m 46s (- 0m 38s) (550 55%) 2.2236\n",
      "0m 46s (- 0m 38s) (551 55%) 3.6686\n",
      "0m 46s (- 0m 38s) (552 55%) 3.7929\n",
      "0m 47s (- 0m 38s) (553 55%) 2.5020\n",
      "0m 47s (- 0m 37s) (554 55%) 3.2506\n",
      "0m 47s (- 0m 37s) (555 55%) 3.2329\n",
      "0m 47s (- 0m 37s) (556 55%) 2.8497\n",
      "0m 47s (- 0m 37s) (557 55%) 3.0882\n",
      "0m 47s (- 0m 37s) (558 55%) 4.2435\n",
      "0m 47s (- 0m 37s) (559 55%) 3.6680\n",
      "0m 47s (- 0m 37s) (560 56%) 2.8248\n",
      "0m 47s (- 0m 37s) (561 56%) 3.3403\n",
      "0m 47s (- 0m 37s) (562 56%) 3.4579\n",
      "0m 48s (- 0m 37s) (563 56%) 3.9803\n",
      "0m 48s (- 0m 37s) (564 56%) 2.0718\n",
      "0m 48s (- 0m 37s) (565 56%) 4.1702\n",
      "0m 48s (- 0m 37s) (566 56%) 2.9828\n",
      "0m 48s (- 0m 37s) (567 56%) 3.7353\n",
      "0m 48s (- 0m 36s) (568 56%) 3.2107\n",
      "0m 48s (- 0m 36s) (569 56%) 5.0093\n",
      "0m 48s (- 0m 36s) (570 56%) 2.9624\n",
      "0m 48s (- 0m 36s) (571 57%) 3.5731\n",
      "0m 48s (- 0m 36s) (572 57%) 3.1860\n",
      "0m 49s (- 0m 36s) (573 57%) 5.3062\n",
      "0m 49s (- 0m 36s) (574 57%) 2.8819\n",
      "0m 49s (- 0m 36s) (575 57%) 2.7105\n",
      "0m 49s (- 0m 36s) (576 57%) 4.0977\n",
      "0m 49s (- 0m 36s) (577 57%) 3.7748\n",
      "0m 49s (- 0m 36s) (578 57%) 3.7631\n",
      "0m 49s (- 0m 36s) (579 57%) 4.8459\n",
      "0m 49s (- 0m 36s) (580 57%) 4.1673\n",
      "0m 49s (- 0m 35s) (581 58%) 2.9841\n",
      "0m 49s (- 0m 35s) (582 58%) 2.3415\n",
      "0m 50s (- 0m 35s) (583 58%) 4.2434\n",
      "0m 50s (- 0m 35s) (584 58%) 5.1194\n",
      "0m 50s (- 0m 35s) (585 58%) 4.1499\n",
      "0m 50s (- 0m 35s) (586 58%) 5.6482\n",
      "0m 50s (- 0m 35s) (587 58%) 2.8632\n",
      "0m 50s (- 0m 35s) (588 58%) 2.8347\n",
      "0m 50s (- 0m 35s) (589 58%) 3.1868\n",
      "0m 50s (- 0m 35s) (590 59%) 3.3645\n",
      "0m 50s (- 0m 35s) (591 59%) 3.0097\n",
      "0m 50s (- 0m 35s) (592 59%) 4.7907\n",
      "0m 50s (- 0m 34s) (593 59%) 2.7641\n",
      "0m 50s (- 0m 34s) (594 59%) 3.1471\n",
      "0m 51s (- 0m 34s) (595 59%) 2.5981\n",
      "0m 51s (- 0m 34s) (596 59%) 3.8598\n",
      "0m 51s (- 0m 34s) (597 59%) 3.1601\n",
      "0m 51s (- 0m 34s) (598 59%) 3.5604\n",
      "0m 51s (- 0m 34s) (599 59%) 4.0785\n",
      "0m 51s (- 0m 34s) (600 60%) 2.4516\n",
      "0m 51s (- 0m 34s) (601 60%) 3.0222\n",
      "0m 51s (- 0m 34s) (602 60%) 2.7643\n",
      "0m 51s (- 0m 34s) (603 60%) 3.8036\n",
      "0m 51s (- 0m 34s) (604 60%) 3.5621\n",
      "0m 51s (- 0m 33s) (605 60%) 4.3944\n",
      "0m 52s (- 0m 33s) (606 60%) 3.0919\n",
      "0m 52s (- 0m 33s) (607 60%) 3.6171\n",
      "0m 52s (- 0m 33s) (608 60%) 3.1359\n",
      "0m 52s (- 0m 33s) (609 60%) 2.2592\n",
      "0m 52s (- 0m 33s) (610 61%) 2.7354\n",
      "0m 52s (- 0m 33s) (611 61%) 2.3164\n",
      "0m 52s (- 0m 33s) (612 61%) 3.5827\n",
      "0m 52s (- 0m 33s) (613 61%) 4.2822\n",
      "0m 52s (- 0m 33s) (614 61%) 4.1276\n",
      "0m 52s (- 0m 33s) (615 61%) 3.2996\n",
      "0m 52s (- 0m 32s) (616 61%) 2.2181\n",
      "0m 53s (- 0m 32s) (617 61%) 3.4851\n",
      "0m 53s (- 0m 32s) (618 61%) 4.3161\n",
      "0m 53s (- 0m 32s) (619 61%) 4.2693\n",
      "0m 53s (- 0m 32s) (620 62%) 1.8589\n",
      "0m 53s (- 0m 32s) (621 62%) 2.6887\n",
      "0m 53s (- 0m 32s) (622 62%) 4.1117\n",
      "0m 53s (- 0m 32s) (623 62%) 3.3003\n",
      "0m 53s (- 0m 32s) (624 62%) 2.5135\n",
      "0m 53s (- 0m 32s) (625 62%) 3.4582\n",
      "0m 53s (- 0m 32s) (626 62%) 2.6466\n",
      "0m 53s (- 0m 32s) (627 62%) 2.4532\n",
      "0m 54s (- 0m 31s) (628 62%) 3.6251\n",
      "0m 54s (- 0m 31s) (629 62%) 3.8191\n",
      "0m 54s (- 0m 31s) (630 63%) 2.3248\n",
      "0m 54s (- 0m 31s) (631 63%) 2.1283\n",
      "0m 54s (- 0m 31s) (632 63%) 2.5980\n",
      "0m 54s (- 0m 31s) (633 63%) 2.4425\n",
      "0m 54s (- 0m 31s) (634 63%) 3.5820\n",
      "0m 54s (- 0m 31s) (635 63%) 4.4985\n",
      "0m 54s (- 0m 31s) (636 63%) 3.0509\n",
      "0m 54s (- 0m 31s) (637 63%) 3.3798\n",
      "0m 54s (- 0m 31s) (638 63%) 3.5828\n",
      "0m 54s (- 0m 31s) (639 63%) 3.9809\n",
      "0m 55s (- 0m 30s) (640 64%) 4.1916\n",
      "0m 55s (- 0m 30s) (641 64%) 4.2210\n",
      "0m 55s (- 0m 30s) (642 64%) 2.7570\n",
      "0m 55s (- 0m 30s) (643 64%) 2.0653\n",
      "0m 55s (- 0m 30s) (644 64%) 2.9466\n",
      "0m 55s (- 0m 30s) (645 64%) 3.6940\n",
      "0m 55s (- 0m 30s) (646 64%) 3.6939\n",
      "0m 55s (- 0m 30s) (647 64%) 4.3767\n",
      "0m 55s (- 0m 30s) (648 64%) 3.4201\n",
      "0m 55s (- 0m 30s) (649 64%) 4.7113\n",
      "0m 55s (- 0m 30s) (650 65%) 2.2948\n",
      "0m 56s (- 0m 30s) (651 65%) 4.4480\n",
      "0m 56s (- 0m 29s) (652 65%) 3.8305\n",
      "0m 56s (- 0m 29s) (653 65%) 4.5143\n",
      "0m 56s (- 0m 29s) (654 65%) 3.4638\n",
      "0m 56s (- 0m 29s) (655 65%) 3.3888\n",
      "0m 56s (- 0m 29s) (656 65%) 4.0591\n",
      "0m 56s (- 0m 29s) (657 65%) 3.2730\n",
      "0m 56s (- 0m 29s) (658 65%) 2.9996\n",
      "0m 56s (- 0m 29s) (659 65%) 2.7855\n",
      "0m 56s (- 0m 29s) (660 66%) 4.4633\n",
      "0m 56s (- 0m 29s) (661 66%) 3.0218\n",
      "0m 56s (- 0m 29s) (662 66%) 4.4534\n",
      "0m 57s (- 0m 29s) (663 66%) 3.9227\n",
      "0m 57s (- 0m 28s) (664 66%) 3.2562\n",
      "0m 57s (- 0m 28s) (665 66%) 2.5958\n",
      "0m 57s (- 0m 28s) (666 66%) 2.8978\n",
      "0m 57s (- 0m 28s) (667 66%) 2.8762\n",
      "0m 57s (- 0m 28s) (668 66%) 4.6757\n",
      "0m 57s (- 0m 28s) (669 66%) 2.9967\n",
      "0m 57s (- 0m 28s) (670 67%) 3.1803\n",
      "0m 57s (- 0m 28s) (671 67%) 3.4784\n",
      "0m 57s (- 0m 28s) (672 67%) 3.3523\n",
      "0m 57s (- 0m 28s) (673 67%) 2.6347\n",
      "0m 57s (- 0m 28s) (674 67%) 4.5894\n",
      "0m 57s (- 0m 27s) (675 67%) 2.6239\n",
      "0m 58s (- 0m 27s) (676 67%) 1.6542\n",
      "0m 58s (- 0m 27s) (677 67%) 3.4598\n",
      "0m 58s (- 0m 27s) (678 67%) 3.0479\n",
      "0m 58s (- 0m 27s) (679 67%) 2.5103\n",
      "0m 58s (- 0m 27s) (680 68%) 2.4417\n",
      "0m 58s (- 0m 27s) (681 68%) 3.3885\n",
      "0m 58s (- 0m 27s) (682 68%) 2.4887\n",
      "0m 58s (- 0m 27s) (683 68%) 3.3647\n",
      "0m 58s (- 0m 27s) (684 68%) 2.8067\n",
      "0m 58s (- 0m 27s) (685 68%) 4.2747\n",
      "0m 58s (- 0m 26s) (686 68%) 2.6881\n",
      "0m 58s (- 0m 26s) (687 68%) 3.0800\n",
      "0m 58s (- 0m 26s) (688 68%) 2.9291\n",
      "0m 59s (- 0m 26s) (689 68%) 4.3869\n",
      "0m 59s (- 0m 26s) (690 69%) 2.5548\n",
      "0m 59s (- 0m 26s) (691 69%) 4.5676\n",
      "0m 59s (- 0m 26s) (692 69%) 4.8600\n",
      "0m 59s (- 0m 26s) (693 69%) 2.8623\n",
      "0m 59s (- 0m 26s) (694 69%) 5.0203\n",
      "0m 59s (- 0m 26s) (695 69%) 3.9238\n",
      "0m 59s (- 0m 26s) (696 69%) 2.4765\n",
      "0m 59s (- 0m 25s) (697 69%) 2.3819\n",
      "0m 59s (- 0m 25s) (698 69%) 3.7047\n",
      "0m 59s (- 0m 25s) (699 69%) 3.5722\n",
      "1m 0s (- 0m 25s) (700 70%) 4.2065\n",
      "1m 0s (- 0m 25s) (701 70%) 2.5602\n",
      "1m 0s (- 0m 25s) (702 70%) 4.6261\n",
      "1m 0s (- 0m 25s) (703 70%) 3.1971\n",
      "1m 0s (- 0m 25s) (704 70%) 3.6137\n",
      "1m 0s (- 0m 25s) (705 70%) 4.5777\n",
      "1m 0s (- 0m 25s) (706 70%) 4.3726\n",
      "1m 0s (- 0m 25s) (707 70%) 2.7600\n",
      "1m 0s (- 0m 25s) (708 70%) 4.1007\n",
      "1m 1s (- 0m 25s) (709 70%) 3.1795\n",
      "1m 1s (- 0m 24s) (710 71%) 2.9190\n",
      "1m 1s (- 0m 24s) (711 71%) 3.3925\n",
      "1m 1s (- 0m 24s) (712 71%) 2.8897\n",
      "1m 1s (- 0m 24s) (713 71%) 4.3588\n",
      "1m 1s (- 0m 24s) (714 71%) 3.5698\n",
      "1m 1s (- 0m 24s) (715 71%) 4.3079\n",
      "1m 1s (- 0m 24s) (716 71%) 3.7296\n",
      "1m 1s (- 0m 24s) (717 71%) 3.8737\n",
      "1m 1s (- 0m 24s) (718 71%) 4.6739\n",
      "1m 2s (- 0m 24s) (719 71%) 3.1686\n",
      "1m 2s (- 0m 24s) (720 72%) 4.4040\n",
      "1m 2s (- 0m 24s) (721 72%) 4.8602\n",
      "1m 2s (- 0m 23s) (722 72%) 3.3496\n",
      "1m 2s (- 0m 23s) (723 72%) 3.1598\n",
      "1m 2s (- 0m 23s) (724 72%) 3.8724\n",
      "1m 2s (- 0m 23s) (725 72%) 2.2424\n",
      "1m 2s (- 0m 23s) (726 72%) 5.4604\n",
      "1m 2s (- 0m 23s) (727 72%) 3.9802\n",
      "1m 2s (- 0m 23s) (728 72%) 3.1160\n",
      "1m 2s (- 0m 23s) (729 72%) 4.2392\n",
      "1m 3s (- 0m 23s) (730 73%) 2.5512\n",
      "1m 3s (- 0m 23s) (731 73%) 2.6368\n",
      "1m 3s (- 0m 23s) (732 73%) 2.6084\n",
      "1m 3s (- 0m 23s) (733 73%) 2.0950\n",
      "1m 3s (- 0m 22s) (734 73%) 2.7649\n",
      "1m 3s (- 0m 22s) (735 73%) 3.1741\n",
      "1m 3s (- 0m 22s) (736 73%) 3.1008\n",
      "1m 3s (- 0m 22s) (737 73%) 4.8085\n",
      "1m 3s (- 0m 22s) (738 73%) 3.2851\n",
      "1m 3s (- 0m 22s) (739 73%) 2.4295\n",
      "1m 3s (- 0m 22s) (740 74%) 3.2125\n",
      "1m 3s (- 0m 22s) (741 74%) 3.5354\n",
      "1m 4s (- 0m 22s) (742 74%) 4.7140\n",
      "1m 4s (- 0m 22s) (743 74%) 4.0483\n",
      "1m 4s (- 0m 22s) (744 74%) 3.0083\n",
      "1m 4s (- 0m 22s) (745 74%) 3.6940\n",
      "1m 4s (- 0m 21s) (746 74%) 3.1763\n",
      "1m 4s (- 0m 21s) (747 74%) 3.6202\n",
      "1m 4s (- 0m 21s) (748 74%) 3.7881\n",
      "1m 4s (- 0m 21s) (749 74%) 2.8845\n",
      "1m 4s (- 0m 21s) (750 75%) 1.7196\n",
      "1m 4s (- 0m 21s) (751 75%) 2.1555\n",
      "1m 5s (- 0m 21s) (752 75%) 2.9376\n",
      "1m 5s (- 0m 21s) (753 75%) 3.8393\n",
      "1m 5s (- 0m 21s) (754 75%) 3.5275\n",
      "1m 5s (- 0m 21s) (755 75%) 2.6434\n",
      "1m 5s (- 0m 21s) (756 75%) 2.3391\n",
      "1m 5s (- 0m 21s) (757 75%) 2.5405\n",
      "1m 5s (- 0m 20s) (758 75%) 3.9919\n",
      "1m 5s (- 0m 20s) (759 75%) 4.1367\n",
      "1m 5s (- 0m 20s) (760 76%) 3.3321\n",
      "1m 5s (- 0m 20s) (761 76%) 4.2520\n",
      "1m 6s (- 0m 20s) (762 76%) 3.5213\n",
      "1m 6s (- 0m 20s) (763 76%) 3.8007\n",
      "1m 6s (- 0m 20s) (764 76%) 2.7853\n",
      "1m 6s (- 0m 20s) (765 76%) 2.3853\n",
      "1m 6s (- 0m 20s) (766 76%) 2.0928\n",
      "1m 6s (- 0m 20s) (767 76%) 4.2897\n",
      "1m 6s (- 0m 20s) (768 76%) 3.5487\n",
      "1m 6s (- 0m 20s) (769 76%) 2.2095\n",
      "1m 7s (- 0m 20s) (770 77%) 2.6927\n",
      "1m 7s (- 0m 19s) (771 77%) 4.2404\n",
      "1m 7s (- 0m 19s) (772 77%) 2.3964\n",
      "1m 7s (- 0m 19s) (773 77%) 4.4225\n",
      "1m 7s (- 0m 19s) (774 77%) 4.0579\n",
      "1m 7s (- 0m 19s) (775 77%) 2.7182\n",
      "1m 7s (- 0m 19s) (776 77%) 3.5204\n",
      "1m 7s (- 0m 19s) (777 77%) 4.5437\n",
      "1m 7s (- 0m 19s) (778 77%) 3.7824\n",
      "1m 8s (- 0m 19s) (779 77%) 1.4060\n",
      "1m 8s (- 0m 19s) (780 78%) 1.9217\n",
      "1m 8s (- 0m 19s) (781 78%) 2.2480\n",
      "1m 8s (- 0m 19s) (782 78%) 2.3768\n",
      "1m 8s (- 0m 18s) (783 78%) 4.5707\n",
      "1m 8s (- 0m 18s) (784 78%) 3.0554\n",
      "1m 8s (- 0m 18s) (785 78%) 2.1487\n",
      "1m 8s (- 0m 18s) (786 78%) 2.9457\n",
      "1m 8s (- 0m 18s) (787 78%) 3.1124\n",
      "1m 8s (- 0m 18s) (788 78%) 4.6317\n",
      "1m 9s (- 0m 18s) (789 78%) 2.8784\n",
      "1m 9s (- 0m 18s) (790 79%) 2.9514\n",
      "1m 9s (- 0m 18s) (791 79%) 4.8805\n",
      "1m 9s (- 0m 18s) (792 79%) 2.3842\n",
      "1m 9s (- 0m 18s) (793 79%) 3.0938\n",
      "1m 9s (- 0m 18s) (794 79%) 4.1862\n",
      "1m 9s (- 0m 17s) (795 79%) 3.1579\n",
      "1m 9s (- 0m 17s) (796 79%) 3.3944\n",
      "1m 9s (- 0m 17s) (797 79%) 3.3569\n",
      "1m 9s (- 0m 17s) (798 79%) 2.9899\n",
      "1m 9s (- 0m 17s) (799 79%) 2.8904\n",
      "1m 10s (- 0m 17s) (800 80%) 2.8078\n",
      "1m 10s (- 0m 17s) (801 80%) 3.7861\n",
      "1m 10s (- 0m 17s) (802 80%) 2.5180\n",
      "1m 10s (- 0m 17s) (803 80%) 4.3580\n",
      "1m 10s (- 0m 17s) (804 80%) 2.7263\n",
      "1m 10s (- 0m 17s) (805 80%) 2.9091\n",
      "1m 10s (- 0m 17s) (806 80%) 3.7612\n",
      "1m 10s (- 0m 16s) (807 80%) 2.5898\n",
      "1m 10s (- 0m 16s) (808 80%) 2.2350\n",
      "1m 10s (- 0m 16s) (809 80%) 2.4219\n",
      "1m 11s (- 0m 16s) (810 81%) 4.2332\n",
      "1m 11s (- 0m 16s) (811 81%) 3.8907\n",
      "1m 11s (- 0m 16s) (812 81%) 2.4155\n",
      "1m 11s (- 0m 16s) (813 81%) 2.3305\n",
      "1m 11s (- 0m 16s) (814 81%) 1.9412\n",
      "1m 11s (- 0m 16s) (815 81%) 3.3655\n",
      "1m 11s (- 0m 16s) (816 81%) 3.9536\n",
      "1m 11s (- 0m 16s) (817 81%) 4.6193\n",
      "1m 11s (- 0m 15s) (818 81%) 3.0935\n",
      "1m 11s (- 0m 15s) (819 81%) 2.4905\n",
      "1m 11s (- 0m 15s) (820 82%) 5.2697\n",
      "1m 12s (- 0m 15s) (821 82%) 3.8649\n",
      "1m 12s (- 0m 15s) (822 82%) 4.4115\n",
      "1m 12s (- 0m 15s) (823 82%) 3.1797\n",
      "1m 12s (- 0m 15s) (824 82%) 3.1557\n",
      "1m 12s (- 0m 15s) (825 82%) 4.1398\n",
      "1m 12s (- 0m 15s) (826 82%) 3.2522\n",
      "1m 12s (- 0m 15s) (827 82%) 4.4407\n",
      "1m 12s (- 0m 15s) (828 82%) 2.7240\n",
      "1m 12s (- 0m 15s) (829 82%) 3.0710\n",
      "1m 12s (- 0m 14s) (830 83%) 2.2366\n",
      "1m 13s (- 0m 14s) (831 83%) 2.5348\n",
      "1m 13s (- 0m 14s) (832 83%) 4.4219\n",
      "1m 13s (- 0m 14s) (833 83%) 2.1439\n",
      "1m 13s (- 0m 14s) (834 83%) 2.3585\n",
      "1m 13s (- 0m 14s) (835 83%) 3.6019\n",
      "1m 13s (- 0m 14s) (836 83%) 3.5331\n",
      "1m 13s (- 0m 14s) (837 83%) 2.1766\n",
      "1m 13s (- 0m 14s) (838 83%) 4.1250\n",
      "1m 13s (- 0m 14s) (839 83%) 3.1932\n",
      "1m 13s (- 0m 14s) (840 84%) 2.0541\n",
      "1m 13s (- 0m 13s) (841 84%) 3.8259\n",
      "1m 14s (- 0m 13s) (842 84%) 3.6615\n",
      "1m 14s (- 0m 13s) (843 84%) 4.0736\n",
      "1m 14s (- 0m 13s) (844 84%) 4.2012\n",
      "1m 14s (- 0m 13s) (845 84%) 3.2588\n",
      "1m 14s (- 0m 13s) (846 84%) 3.3913\n",
      "1m 14s (- 0m 13s) (847 84%) 2.9244\n",
      "1m 14s (- 0m 13s) (848 84%) 4.0747\n",
      "1m 14s (- 0m 13s) (849 84%) 2.9243\n",
      "1m 14s (- 0m 13s) (850 85%) 4.2388\n",
      "1m 15s (- 0m 13s) (851 85%) 3.4414\n",
      "1m 15s (- 0m 13s) (852 85%) 2.0783\n",
      "1m 15s (- 0m 12s) (853 85%) 4.9135\n",
      "1m 15s (- 0m 12s) (854 85%) 2.4034\n",
      "1m 15s (- 0m 12s) (855 85%) 4.1589\n",
      "1m 15s (- 0m 12s) (856 85%) 3.8009\n",
      "1m 15s (- 0m 12s) (857 85%) 3.4974\n",
      "1m 15s (- 0m 12s) (858 85%) 3.0073\n",
      "1m 15s (- 0m 12s) (859 85%) 2.7084\n",
      "1m 15s (- 0m 12s) (860 86%) 2.6643\n",
      "1m 15s (- 0m 12s) (861 86%) 4.7920\n",
      "1m 15s (- 0m 12s) (862 86%) 2.8069\n",
      "1m 15s (- 0m 12s) (863 86%) 2.9715\n",
      "1m 15s (- 0m 11s) (864 86%) 2.1826\n",
      "1m 16s (- 0m 11s) (865 86%) 3.1822\n",
      "1m 16s (- 0m 11s) (866 86%) 2.8147\n",
      "1m 16s (- 0m 11s) (867 86%) 2.5635\n",
      "1m 16s (- 0m 11s) (868 86%) 1.9674\n",
      "1m 16s (- 0m 11s) (869 86%) 5.1811\n",
      "1m 16s (- 0m 11s) (870 87%) 3.4924\n",
      "1m 16s (- 0m 11s) (871 87%) 2.2728\n",
      "1m 16s (- 0m 11s) (872 87%) 3.9578\n",
      "1m 16s (- 0m 11s) (873 87%) 3.0831\n",
      "1m 16s (- 0m 11s) (874 87%) 3.7939\n",
      "1m 16s (- 0m 10s) (875 87%) 3.8825\n",
      "1m 17s (- 0m 10s) (876 87%) 3.1760\n",
      "1m 17s (- 0m 10s) (877 87%) 2.8728\n",
      "1m 17s (- 0m 10s) (878 87%) 3.6343\n",
      "1m 17s (- 0m 10s) (879 87%) 2.3000\n",
      "1m 17s (- 0m 10s) (880 88%) 3.3969\n",
      "1m 17s (- 0m 10s) (881 88%) 3.6800\n",
      "1m 17s (- 0m 10s) (882 88%) 3.9002\n",
      "1m 17s (- 0m 10s) (883 88%) 4.0086\n",
      "1m 17s (- 0m 10s) (884 88%) 3.1739\n",
      "1m 18s (- 0m 10s) (885 88%) 4.6969\n",
      "1m 18s (- 0m 10s) (886 88%) 2.4219\n",
      "1m 18s (- 0m 9s) (887 88%) 3.1720\n",
      "1m 18s (- 0m 9s) (888 88%) 3.8066\n",
      "1m 18s (- 0m 9s) (889 88%) 2.8315\n",
      "1m 18s (- 0m 9s) (890 89%) 3.7559\n",
      "1m 18s (- 0m 9s) (891 89%) 2.9528\n",
      "1m 18s (- 0m 9s) (892 89%) 3.5953\n",
      "1m 18s (- 0m 9s) (893 89%) 2.1080\n",
      "1m 18s (- 0m 9s) (894 89%) 4.2125\n",
      "1m 18s (- 0m 9s) (895 89%) 2.6970\n",
      "1m 18s (- 0m 9s) (896 89%) 3.0089\n",
      "1m 19s (- 0m 9s) (897 89%) 4.1211\n",
      "1m 19s (- 0m 8s) (898 89%) 2.3168\n",
      "1m 19s (- 0m 8s) (899 89%) 1.8421\n",
      "1m 19s (- 0m 8s) (900 90%) 2.6238\n",
      "1m 19s (- 0m 8s) (901 90%) 2.5893\n",
      "1m 19s (- 0m 8s) (902 90%) 2.9809\n",
      "1m 19s (- 0m 8s) (903 90%) 4.0357\n",
      "1m 19s (- 0m 8s) (904 90%) 3.4390\n",
      "1m 19s (- 0m 8s) (905 90%) 4.3642\n",
      "1m 19s (- 0m 8s) (906 90%) 3.9864\n",
      "1m 19s (- 0m 8s) (907 90%) 2.6279\n",
      "1m 19s (- 0m 8s) (908 90%) 3.7174\n",
      "1m 20s (- 0m 8s) (909 90%) 4.4934\n",
      "1m 20s (- 0m 7s) (910 91%) 3.7263\n",
      "1m 20s (- 0m 7s) (911 91%) 2.3982\n",
      "1m 20s (- 0m 7s) (912 91%) 4.1513\n",
      "1m 20s (- 0m 7s) (913 91%) 2.5121\n",
      "1m 20s (- 0m 7s) (914 91%) 1.9915\n",
      "1m 20s (- 0m 7s) (915 91%) 2.6973\n",
      "1m 20s (- 0m 7s) (916 91%) 3.0425\n",
      "1m 20s (- 0m 7s) (917 91%) 3.3680\n",
      "1m 20s (- 0m 7s) (918 91%) 2.9470\n",
      "1m 20s (- 0m 7s) (919 91%) 2.9981\n",
      "1m 20s (- 0m 7s) (920 92%) 3.4718\n",
      "1m 21s (- 0m 6s) (921 92%) 3.9881\n",
      "1m 21s (- 0m 6s) (922 92%) 2.9809\n",
      "1m 21s (- 0m 6s) (923 92%) 2.5289\n",
      "1m 21s (- 0m 6s) (924 92%) 4.5802\n",
      "1m 21s (- 0m 6s) (925 92%) 3.1911\n",
      "1m 21s (- 0m 6s) (926 92%) 2.9080\n",
      "1m 21s (- 0m 6s) (927 92%) 3.4888\n",
      "1m 21s (- 0m 6s) (928 92%) 3.7113\n",
      "1m 21s (- 0m 6s) (929 92%) 2.4146\n",
      "1m 21s (- 0m 6s) (930 93%) 3.2765\n",
      "1m 21s (- 0m 6s) (931 93%) 4.2519\n",
      "1m 22s (- 0m 5s) (932 93%) 2.0790\n",
      "1m 22s (- 0m 5s) (933 93%) 2.8204\n",
      "1m 22s (- 0m 5s) (934 93%) 2.4236\n",
      "1m 22s (- 0m 5s) (935 93%) 4.4294\n",
      "1m 22s (- 0m 5s) (936 93%) 1.4507\n",
      "1m 22s (- 0m 5s) (937 93%) 4.2588\n",
      "1m 22s (- 0m 5s) (938 93%) 3.8764\n",
      "1m 22s (- 0m 5s) (939 93%) 3.2276\n",
      "1m 22s (- 0m 5s) (940 94%) 4.1732\n",
      "1m 22s (- 0m 5s) (941 94%) 2.2841\n",
      "1m 23s (- 0m 5s) (942 94%) 1.9192\n",
      "1m 23s (- 0m 5s) (943 94%) 2.6374\n",
      "1m 23s (- 0m 4s) (944 94%) 3.7552\n",
      "1m 23s (- 0m 4s) (945 94%) 1.9893\n",
      "1m 23s (- 0m 4s) (946 94%) 2.7402\n",
      "1m 23s (- 0m 4s) (947 94%) 2.7007\n",
      "1m 23s (- 0m 4s) (948 94%) 2.4711\n",
      "1m 23s (- 0m 4s) (949 94%) 4.2425\n",
      "1m 23s (- 0m 4s) (950 95%) 3.6158\n",
      "1m 23s (- 0m 4s) (951 95%) 2.5174\n",
      "1m 24s (- 0m 4s) (952 95%) 2.6064\n",
      "1m 24s (- 0m 4s) (953 95%) 2.2501\n",
      "1m 24s (- 0m 4s) (954 95%) 2.9420\n",
      "1m 24s (- 0m 3s) (955 95%) 3.8902\n",
      "1m 24s (- 0m 3s) (956 95%) 2.8970\n",
      "1m 24s (- 0m 3s) (957 95%) 2.0798\n",
      "1m 24s (- 0m 3s) (958 95%) 2.8090\n",
      "1m 24s (- 0m 3s) (959 95%) 3.7052\n",
      "1m 24s (- 0m 3s) (960 96%) 2.8609\n",
      "1m 25s (- 0m 3s) (961 96%) 3.6865\n",
      "1m 25s (- 0m 3s) (962 96%) 3.1510\n",
      "1m 25s (- 0m 3s) (963 96%) 3.3076\n",
      "1m 25s (- 0m 3s) (964 96%) 4.5976\n",
      "1m 25s (- 0m 3s) (965 96%) 3.2731\n",
      "1m 25s (- 0m 3s) (966 96%) 4.9963\n",
      "1m 25s (- 0m 2s) (967 96%) 4.2704\n",
      "1m 25s (- 0m 2s) (968 96%) 4.3986\n",
      "1m 25s (- 0m 2s) (969 96%) 2.1074\n",
      "1m 25s (- 0m 2s) (970 97%) 3.2904\n",
      "1m 25s (- 0m 2s) (971 97%) 2.9928\n",
      "1m 25s (- 0m 2s) (972 97%) 4.2389\n",
      "1m 26s (- 0m 2s) (973 97%) 3.4194\n",
      "1m 26s (- 0m 2s) (974 97%) 3.9248\n",
      "1m 26s (- 0m 2s) (975 97%) 3.4658\n",
      "1m 26s (- 0m 2s) (976 97%) 1.8196\n",
      "1m 26s (- 0m 2s) (977 97%) 4.1762\n",
      "1m 26s (- 0m 1s) (978 97%) 2.4667\n",
      "1m 26s (- 0m 1s) (979 97%) 2.6186\n",
      "1m 26s (- 0m 1s) (980 98%) 3.7193\n",
      "1m 26s (- 0m 1s) (981 98%) 2.0875\n",
      "1m 26s (- 0m 1s) (982 98%) 2.5964\n",
      "1m 26s (- 0m 1s) (983 98%) 2.7314\n",
      "1m 27s (- 0m 1s) (984 98%) 1.6652\n",
      "1m 27s (- 0m 1s) (985 98%) 2.8421\n",
      "1m 27s (- 0m 1s) (986 98%) 4.0029\n",
      "1m 27s (- 0m 1s) (987 98%) 2.6707\n",
      "1m 27s (- 0m 1s) (988 98%) 2.7534\n",
      "1m 27s (- 0m 0s) (989 98%) 2.9873\n",
      "1m 27s (- 0m 0s) (990 99%) 3.1583\n",
      "1m 27s (- 0m 0s) (991 99%) 1.5437\n",
      "1m 27s (- 0m 0s) (992 99%) 2.3769\n",
      "1m 27s (- 0m 0s) (993 99%) 4.0456\n",
      "1m 28s (- 0m 0s) (994 99%) 4.4777\n",
      "1m 28s (- 0m 0s) (995 99%) 3.4332\n",
      "1m 28s (- 0m 0s) (996 99%) 2.4580\n",
      "1m 28s (- 0m 0s) (997 99%) 2.7583\n",
      "1m 28s (- 0m 0s) (998 99%) 3.8526\n",
      "1m 28s (- 0m 0s) (999 99%) 3.7624\n",
      "1m 28s (- 0m 0s) (1000 100%) 2.9190\n"
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words,\n",
    "                               1, dropout_p=0.1)\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda()\n",
    "    attn_decoder1 = attn_decoder1.cuda()\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 1000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
